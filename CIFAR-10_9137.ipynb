{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e0c9bf6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0c9bf6a",
        "outputId": "db3b88d2-ed63-4f89-9973-9c840524a3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c2bc689e",
      "metadata": {
        "id": "c2bc689e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "39bf0669",
      "metadata": {
        "id": "39bf0669"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Backbone Block\n",
        "class block(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels, r):\n",
        "        super(block, self).__init__()\n",
        "        \n",
        "        # SpatialAvgeragePool\n",
        "        # Use AdaptiveAvgPool2d to calculate spatial average of each channel\n",
        "        # (1,1) is the output size, meaning that it will return an element per channel\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        \n",
        "        # In the block there are 4 convolutions layers \n",
        "        # The vector resulted from SpatialAveragePool is passed into MLP to predict a vector of 4 elements\n",
        "        self.linear1 = nn.Linear(input_channels, output_channels//r)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(output_channels//r, 4)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        # Define the 4 convolution layers and Batch Normalisaton (BN) layers\n",
        "        # Each convolution layer has different specification to capture details in different scales\n",
        "        # Conv1 is just a 1x1 convolution\n",
        "        # Conv2 has a 3x3 kernel with 1 padding to maintain same output size\n",
        "        # Conv3 has a 5x5 kernel with 2 padding to maintain same output size\n",
        "        # Conv4 is first applied a 3x3 Max Pooling with 1 padding, followed by a 1x1 convolution\n",
        "        self.conv1 = nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(input_channels, output_channels, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(input_channels, output_channels, kernel_size=1)\n",
        "        self.max = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(input_channels, output_channels, kernel_size=1)\n",
        "\n",
        "        self.bn = nn.LazyBatchNorm2d()\n",
        "        self.bn1 = nn.LazyBatchNorm2d()\n",
        "        self.bn2 = nn.LazyBatchNorm2d()\n",
        "        self.bn3 = nn.LazyBatchNorm2d()\n",
        "        self.bn4 = nn.LazyBatchNorm2d()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        a = self.avg_pool(x).flatten(1) # SpatialAveregePool, flatten it to pass into the MLP\n",
        "        a = self.relu(self.linear1(a)) # First linear layer, activated by ReLU\n",
        "        a = self.sigmoid(self.linear2(a))# Second linear layer, activated by Sigmoid\n",
        "        \n",
        "        a0 = torch.split(a, 1, dim=1)[0] # Extract a1,a2,a3,a4 from vector a, from (batch_size,4) to (batch_size,1)\n",
        "        a0 = torch.unsqueeze(a0, dim=1) # Unsqueeze it to match the tensor dimension (batch_size,1,1,1)\n",
        "        a0 = torch.unsqueeze(a0, dim=2)\n",
        "        \n",
        "        a1 = torch.split(a, 1, dim=1)[1]\n",
        "        a1 = torch.unsqueeze(a1, dim=1)\n",
        "        a1 = torch.unsqueeze(a1, dim=2)\n",
        "        \n",
        "        a2 = torch.split(a, 1, dim=1)[2]\n",
        "        a2 = torch.unsqueeze(a2, dim=1)\n",
        "        a2 = torch.unsqueeze(a2, dim=2)\n",
        "        \n",
        "        a3 = torch.split(a, 1, dim=1)[3]\n",
        "        a3 = torch.unsqueeze(a3, dim=1)\n",
        "        a3 = torch.unsqueeze(a3, dim=2)\n",
        "        \n",
        "        # Each convolution layer is activated by ReLU and followed by BN\n",
        "        b1 = self.relu(self.bn1(self.conv1(x)))\n",
        "        b2 = self.relu(self.bn2(self.conv2(x)))\n",
        "        b3 = self.relu(self.bn3(self.conv3(x)))\n",
        "        b4 = self.relu(self.bn4(self.conv4(self.max(x))))\n",
        "        \n",
        "        # Results from the 4 convolution layers are combined using vector a\n",
        "        # Feature maps from each convolution are multiplied with an element of vector a and are added together\n",
        "        # Output of the block = a1*conv1 + a2*conv2 +a3*conv3 + a4*conv4\n",
        "        # The output is activated by ReLU\n",
        "        out = b1*a0 + b2*a1 + b3*a2 + b4*a3\n",
        "        out = self.bn(out)\n",
        "        return out "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dd80033d",
      "metadata": {
        "id": "dd80033d"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        # Construct a stem with a convolution layer activated by ReLU\n",
        "        # the 3-channel RGB images will first turn into 16 output channels\n",
        "        self.stem = nn.Sequential(nn.Conv2d(3,16,kernel_size=3, padding=1),\n",
        "                                  nn.ReLU())\n",
        "        \n",
        "        # Construct the blocks by defining the input and output channels\n",
        "        self.block1 = block(16,64,8)\n",
        "        self.block2 = block(64,256,8)\n",
        "        self.block3 = block(256,512,16)\n",
        "        self.block4 = block(512,1024,16)\n",
        "        self.block5 = block(1024,2048,32)\n",
        "\n",
        "        # Define a 2x2 Max Pooling, stride 2 layer\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # The Classifier\n",
        "        # Again, use AdaptiveAvgPool2d to calculate spatial average of each channel\n",
        "        # Flatten it and pass it to Softmax regression classifier\n",
        "        self.classifier = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), \n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Dropout(0.3),\n",
        "                                        nn.Linear(2048, 10))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = self.stem(out)\n",
        "        out = self.block1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.max_pool(out) # Max Pooling is applied to reduce spatial dimension between blocks\n",
        "        out = self.block3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.max_pool(out)\n",
        "        out = self.block4(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.max_pool(out)\n",
        "        out = self.block5(out)\n",
        "\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bf52894e",
      "metadata": {
        "id": "bf52894e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "debf8f93-3609-422a-94d7-9fa9100e6eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ],
      "source": [
        "net = CNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "712c9af1",
      "metadata": {
        "id": "712c9af1"
      },
      "outputs": [],
      "source": [
        "# Initialize the weights\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "564053df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "564053df",
        "outputId": "56721b1d-5cfc-4a1d-dfe7-a9aa4ad30e58",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (block1): block(\n",
              "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (linear1): Linear(in_features=16, out_features=8, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (linear2): Linear(in_features=8, out_features=4, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "    (conv1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2): Conv2d(16, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (max): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (conv4): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn3): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn4): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (block2): block(\n",
              "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "    (conv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (max): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (conv4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn3): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn4): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (block3): block(\n",
              "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (linear1): Linear(in_features=256, out_features=32, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (max): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (conv4): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn3): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn4): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (block4): block(\n",
              "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (linear1): Linear(in_features=512, out_features=64, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (linear2): Linear(in_features=64, out_features=4, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2): Conv2d(512, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (max): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (conv4): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn3): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn4): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (block5): block(\n",
              "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (linear1): Linear(in_features=1024, out_features=64, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (linear2): Linear(in_features=64, out_features=4, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "    (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2): Conv2d(1024, 2048, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (max): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (conv4): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn3): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn4): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (relu): ReLU()\n",
              "  (classifier): Sequential(\n",
              "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Dropout(p=0.3, inplace=False)\n",
              "    (3): Linear(in_features=2048, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "net.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6215dee8",
      "metadata": {
        "id": "6215dee8"
      },
      "outputs": [],
      "source": [
        "# Define Image Augumentation on the training set to improve performance\n",
        "# source: https://www.kaggle.com/code/vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(size=32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(), # Randomly flip the image horizontally\n",
        "                                      transforms.RandomRotation(10),     # Randomly rotate the image to a specified angel\n",
        "                                      transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), # Performs actions like zooms, change shear angles.\n",
        "                                      transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n",
        "                                      transforms.ToTensor(), # Convert the image to Tensors for processing\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize the values of all the images\n",
        "                                      ])\n",
        "\n",
        "# For the test set, only convert the images to Tensors and normalize the values\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "205e8ebf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "205e8ebf",
        "outputId": "1a7c4368-7d3a-45f1-9dae-9c8fbee231a7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 48453460.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset and apply the transformation\n",
        "# source: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=cifar\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e15a1e91",
      "metadata": {
        "id": "e15a1e91"
      },
      "outputs": [],
      "source": [
        "# Define the learning rate, number of epochs and batch size\n",
        "lr, num_epochs, batch_size = 0.005, 60, 32\n",
        "\n",
        "train_iter = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "test_iter = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3fbca16a",
      "metadata": {
        "id": "3fbca16a"
      },
      "outputs": [],
      "source": [
        "# Training script\n",
        "# source: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
        "\n",
        "def train_loop(train_iter, test_iter, net, num_epochs, loss, optimizer, device):\n",
        "    # Create empty lists to store training results for plotting\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_acc = []\n",
        "    \n",
        "    net.to(device) # Make sure the model is in the device\n",
        "    \n",
        "    for i in range(num_epochs):\n",
        "        net.train() # set to training mode\n",
        "        train_loss, train_correct = 0, 0\n",
        "        print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "        train_size = len(train_iter.dataset) # number of training samples\n",
        "        for batch, (X, y) in enumerate(train_iter):\n",
        "            # Compute prediction and loss\n",
        "            train_num_batches = len(train_iter) # number of batches in training set\n",
        "            X, y = X.to(device), y.to(device) # Make sure the tensors are also in the same device\n",
        "            pred = net(X)\n",
        "            l = loss(pred, y)\n",
        "            train_correct += (pred.argmax(1) == y).type(torch.float).sum().item() # sum of correct predictions\n",
        "            train_loss += l.item() # total training loss in each epoch\n",
        "            \n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if batch % 200 == 199: # show update for every 100 batches\n",
        "                # loss in this batch and number of samples trained in this epoch\n",
        "                l, current = l.item(), (batch + 1) * len(X)\n",
        "                print(f\"loss: {l:>7f}  [{current:>5d}/{train_size:>5d}]\")\n",
        "                \n",
        "        # For each epoch, \n",
        "        # the average training loss is the total loss of all batches divided by the number of batches;\n",
        "        # the training accuracy is the total number of correct predictions divided by the numbers of training samples\n",
        "        train_loss /= train_num_batches\n",
        "        train_correct /= train_size\n",
        "        \n",
        "        # Append the values to the lists for plotting\n",
        "        train_losses.append(train_loss)\n",
        "        train_acc.append(train_correct)\n",
        "        print(f\"Train Accuracy: {train_correct:>3f}, Train Avg loss: {train_loss:>7f}\")\n",
        "        \n",
        "        # For evaluation, first set it to evaluation mode\n",
        "        net.eval()\n",
        "        if not device:\n",
        "            device = next(iter(net.parameters())).device\n",
        "            \n",
        "        size = len(test_iter.dataset) # number of test samples\n",
        "        num_batches = len(test_iter) # number of batches in test set\n",
        "        test_loss, test_correct = 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X, y in test_iter:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                pred = net(X)\n",
        "                test_loss += loss(pred, y).item() # calculate total test loss in each epoch\n",
        "                test_correct += (pred.argmax(1) == y).type(torch.float).sum().item() # sum of correct predictions\n",
        "\n",
        "        # Similarly, \n",
        "        # the average test loss is the total loss of all batches divided by the number of batches;\n",
        "        # the test accuracy is the total number of correct predictions divided by the numbers of test samples\n",
        "        test_loss /= num_batches\n",
        "        test_correct /= size\n",
        "        if i > 0:\n",
        "            if test_correct > max(test_acc) and test_correct > 0.9:\n",
        "                PATH = f'./cifar_{test_correct*10000:.0f}.pth'\n",
        "                torch.save(net, PATH)\n",
        "                print('Model saved!')\n",
        "        test_acc.append(test_correct) # Append test accuracy to the lists for plotting\n",
        "        print(f\"Test Accuracy: {test_correct:>3f}, Test Avg loss: {test_loss:>8f} \\n\")\n",
        "          \n",
        "    \n",
        "    # Plot the curves\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(train_losses, color='blue', linestyle='-', label=\"train loss\")\n",
        "    plt.plot(train_acc, color='red', linestyle=':', label=\"train acc\")\n",
        "    plt.plot(test_acc, color='green', linestyle='--', label=\"test acc\")\n",
        "    \n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print(f'Training finished. The highest validation accuracy is {max(test_acc)}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "248e8e3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "248e8e3b",
        "outputId": "0f44387f-2d74-4455-f9d1-97615bc7a88b",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Tesla T4\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.827053  [ 6400/50000]\n",
            "loss: 1.496648  [12800/50000]\n",
            "loss: 1.702716  [19200/50000]\n",
            "loss: 1.592972  [25600/50000]\n",
            "loss: 1.245253  [32000/50000]\n",
            "loss: 1.690328  [38400/50000]\n",
            "loss: 1.085090  [44800/50000]\n",
            "Train Accuracy: 0.448440, Train Avg loss: 1.542224\n",
            "Test Accuracy: 0.584100, Test Avg loss: 1.188408 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.044629  [ 6400/50000]\n",
            "loss: 1.001892  [12800/50000]\n",
            "loss: 1.503025  [19200/50000]\n",
            "loss: 1.045212  [25600/50000]\n",
            "loss: 1.157553  [32000/50000]\n",
            "loss: 0.800478  [38400/50000]\n",
            "loss: 1.059570  [44800/50000]\n",
            "Train Accuracy: 0.623360, Train Avg loss: 1.071822\n",
            "Test Accuracy: 0.704500, Test Avg loss: 0.828980 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.860533  [ 6400/50000]\n",
            "loss: 1.002791  [12800/50000]\n",
            "loss: 1.127401  [19200/50000]\n",
            "loss: 0.718570  [25600/50000]\n",
            "loss: 0.607569  [32000/50000]\n",
            "loss: 1.046333  [38400/50000]\n",
            "loss: 0.859350  [44800/50000]\n",
            "Train Accuracy: 0.685700, Train Avg loss: 0.901649\n",
            "Test Accuracy: 0.763900, Test Avg loss: 0.683906 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.752924  [ 6400/50000]\n",
            "loss: 0.899646  [12800/50000]\n",
            "loss: 0.730639  [19200/50000]\n",
            "loss: 0.883071  [25600/50000]\n",
            "loss: 0.449271  [32000/50000]\n",
            "loss: 0.694170  [38400/50000]\n",
            "loss: 1.237308  [44800/50000]\n",
            "Train Accuracy: 0.721940, Train Avg loss: 0.803073\n",
            "Test Accuracy: 0.789400, Test Avg loss: 0.621426 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.912833  [ 6400/50000]\n",
            "loss: 0.526319  [12800/50000]\n",
            "loss: 0.570478  [19200/50000]\n",
            "loss: 0.716645  [25600/50000]\n",
            "loss: 0.925848  [32000/50000]\n",
            "loss: 0.454670  [38400/50000]\n",
            "loss: 0.878548  [44800/50000]\n",
            "Train Accuracy: 0.743400, Train Avg loss: 0.743886\n",
            "Test Accuracy: 0.820900, Test Avg loss: 0.531896 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.901497  [ 6400/50000]\n",
            "loss: 0.650477  [12800/50000]\n",
            "loss: 0.494482  [19200/50000]\n",
            "loss: 0.384007  [25600/50000]\n",
            "loss: 0.708612  [32000/50000]\n",
            "loss: 0.629302  [38400/50000]\n",
            "loss: 0.880440  [44800/50000]\n",
            "Train Accuracy: 0.764600, Train Avg loss: 0.685487\n",
            "Test Accuracy: 0.835500, Test Avg loss: 0.495502 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.489856  [ 6400/50000]\n",
            "loss: 0.927496  [12800/50000]\n",
            "loss: 0.497601  [19200/50000]\n",
            "loss: 1.114383  [25600/50000]\n",
            "loss: 0.625115  [32000/50000]\n",
            "loss: 0.582804  [38400/50000]\n",
            "loss: 0.337658  [44800/50000]\n",
            "Train Accuracy: 0.777860, Train Avg loss: 0.644415\n",
            "Test Accuracy: 0.833700, Test Avg loss: 0.489195 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.457198  [ 6400/50000]\n",
            "loss: 0.877037  [12800/50000]\n",
            "loss: 0.519978  [19200/50000]\n",
            "loss: 0.359236  [25600/50000]\n",
            "loss: 0.472093  [32000/50000]\n",
            "loss: 0.563410  [38400/50000]\n",
            "loss: 0.711228  [44800/50000]\n",
            "Train Accuracy: 0.790120, Train Avg loss: 0.607758\n",
            "Test Accuracy: 0.847600, Test Avg loss: 0.443707 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.879634  [ 6400/50000]\n",
            "loss: 0.631970  [12800/50000]\n",
            "loss: 0.408438  [19200/50000]\n",
            "loss: 0.487059  [25600/50000]\n",
            "loss: 0.391024  [32000/50000]\n",
            "loss: 0.312391  [38400/50000]\n",
            "loss: 0.776126  [44800/50000]\n",
            "Train Accuracy: 0.801140, Train Avg loss: 0.577941\n",
            "Test Accuracy: 0.853300, Test Avg loss: 0.441450 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.905132  [ 6400/50000]\n",
            "loss: 0.755562  [12800/50000]\n",
            "loss: 0.533275  [19200/50000]\n",
            "loss: 0.580187  [25600/50000]\n",
            "loss: 0.537439  [32000/50000]\n",
            "loss: 0.491438  [38400/50000]\n",
            "loss: 0.295104  [44800/50000]\n",
            "Train Accuracy: 0.809940, Train Avg loss: 0.549842\n",
            "Test Accuracy: 0.855500, Test Avg loss: 0.441938 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.395086  [ 6400/50000]\n",
            "loss: 0.600191  [12800/50000]\n",
            "loss: 0.624303  [19200/50000]\n",
            "loss: 0.545258  [25600/50000]\n",
            "loss: 0.647811  [32000/50000]\n",
            "loss: 0.697505  [38400/50000]\n",
            "loss: 0.289069  [44800/50000]\n",
            "Train Accuracy: 0.817400, Train Avg loss: 0.533347\n",
            "Test Accuracy: 0.862200, Test Avg loss: 0.402218 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.781745  [ 6400/50000]\n",
            "loss: 0.405987  [12800/50000]\n",
            "loss: 0.376282  [19200/50000]\n",
            "loss: 0.390885  [25600/50000]\n",
            "loss: 0.356703  [32000/50000]\n",
            "loss: 0.494239  [38400/50000]\n",
            "loss: 0.850026  [44800/50000]\n",
            "Train Accuracy: 0.823860, Train Avg loss: 0.510288\n",
            "Test Accuracy: 0.862300, Test Avg loss: 0.414360 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.392796  [ 6400/50000]\n",
            "loss: 0.405162  [12800/50000]\n",
            "loss: 0.367956  [19200/50000]\n",
            "loss: 0.602206  [25600/50000]\n",
            "loss: 0.873135  [32000/50000]\n",
            "loss: 0.757347  [38400/50000]\n",
            "loss: 0.353000  [44800/50000]\n",
            "Train Accuracy: 0.831560, Train Avg loss: 0.491391\n",
            "Test Accuracy: 0.869300, Test Avg loss: 0.399935 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.809873  [ 6400/50000]\n",
            "loss: 0.449065  [12800/50000]\n",
            "loss: 0.287827  [19200/50000]\n",
            "loss: 0.289262  [25600/50000]\n",
            "loss: 0.357469  [32000/50000]\n",
            "loss: 0.477004  [38400/50000]\n",
            "loss: 0.664268  [44800/50000]\n",
            "Train Accuracy: 0.837120, Train Avg loss: 0.473781\n",
            "Test Accuracy: 0.869700, Test Avg loss: 0.397124 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.569619  [ 6400/50000]\n",
            "loss: 0.657673  [12800/50000]\n",
            "loss: 0.354135  [19200/50000]\n",
            "loss: 0.950180  [25600/50000]\n",
            "loss: 0.255431  [32000/50000]\n",
            "loss: 0.574373  [38400/50000]\n",
            "loss: 0.352684  [44800/50000]\n",
            "Train Accuracy: 0.841220, Train Avg loss: 0.458387\n",
            "Test Accuracy: 0.865000, Test Avg loss: 0.408119 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.420728  [ 6400/50000]\n",
            "loss: 0.333415  [12800/50000]\n",
            "loss: 0.476931  [19200/50000]\n",
            "loss: 0.460437  [25600/50000]\n",
            "loss: 0.380909  [32000/50000]\n",
            "loss: 0.425400  [38400/50000]\n",
            "loss: 0.462240  [44800/50000]\n",
            "Train Accuracy: 0.846000, Train Avg loss: 0.444876\n",
            "Test Accuracy: 0.874700, Test Avg loss: 0.382523 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.467663  [ 6400/50000]\n",
            "loss: 0.311082  [12800/50000]\n",
            "loss: 0.365663  [19200/50000]\n",
            "loss: 0.705305  [25600/50000]\n",
            "loss: 0.335092  [32000/50000]\n",
            "loss: 0.449896  [38400/50000]\n",
            "loss: 0.385381  [44800/50000]\n",
            "Train Accuracy: 0.851320, Train Avg loss: 0.433560\n",
            "Test Accuracy: 0.886100, Test Avg loss: 0.341522 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.432739  [ 6400/50000]\n",
            "loss: 0.563431  [12800/50000]\n",
            "loss: 0.200514  [19200/50000]\n",
            "loss: 0.494776  [25600/50000]\n",
            "loss: 0.718320  [32000/50000]\n",
            "loss: 0.260880  [38400/50000]\n",
            "loss: 0.715520  [44800/50000]\n",
            "Train Accuracy: 0.856260, Train Avg loss: 0.418759\n",
            "Test Accuracy: 0.881900, Test Avg loss: 0.367447 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.353210  [ 6400/50000]\n",
            "loss: 0.200998  [12800/50000]\n",
            "loss: 0.481569  [19200/50000]\n",
            "loss: 0.372532  [25600/50000]\n",
            "loss: 0.603938  [32000/50000]\n",
            "loss: 0.762674  [38400/50000]\n",
            "loss: 0.578401  [44800/50000]\n",
            "Train Accuracy: 0.860500, Train Avg loss: 0.406829\n",
            "Test Accuracy: 0.885900, Test Avg loss: 0.356011 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.321364  [ 6400/50000]\n",
            "loss: 0.546896  [12800/50000]\n",
            "loss: 0.304786  [19200/50000]\n",
            "loss: 0.370940  [25600/50000]\n",
            "loss: 0.291606  [32000/50000]\n",
            "loss: 0.746232  [38400/50000]\n",
            "loss: 0.618170  [44800/50000]\n",
            "Train Accuracy: 0.863000, Train Avg loss: 0.396158\n",
            "Test Accuracy: 0.881000, Test Avg loss: 0.371227 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.582509  [ 6400/50000]\n",
            "loss: 0.594589  [12800/50000]\n",
            "loss: 0.194585  [19200/50000]\n",
            "loss: 0.472490  [25600/50000]\n",
            "loss: 0.201616  [32000/50000]\n",
            "loss: 0.610370  [38400/50000]\n",
            "loss: 0.581142  [44800/50000]\n",
            "Train Accuracy: 0.866320, Train Avg loss: 0.388283\n",
            "Test Accuracy: 0.883300, Test Avg loss: 0.354992 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.415037  [ 6400/50000]\n",
            "loss: 0.409475  [12800/50000]\n",
            "loss: 0.417192  [19200/50000]\n",
            "loss: 0.547739  [25600/50000]\n",
            "loss: 0.220185  [32000/50000]\n",
            "loss: 0.106732  [38400/50000]\n",
            "loss: 0.308439  [44800/50000]\n",
            "Train Accuracy: 0.870560, Train Avg loss: 0.374821\n",
            "Test Accuracy: 0.884500, Test Avg loss: 0.368300 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.768115  [ 6400/50000]\n",
            "loss: 0.518989  [12800/50000]\n",
            "loss: 0.382054  [19200/50000]\n",
            "loss: 0.114913  [25600/50000]\n",
            "loss: 0.189418  [32000/50000]\n",
            "loss: 0.204123  [38400/50000]\n",
            "loss: 0.349050  [44800/50000]\n",
            "Train Accuracy: 0.874080, Train Avg loss: 0.369170\n",
            "Test Accuracy: 0.889500, Test Avg loss: 0.355301 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.223306  [ 6400/50000]\n",
            "loss: 0.297492  [12800/50000]\n",
            "loss: 0.707019  [19200/50000]\n",
            "loss: 0.376396  [25600/50000]\n",
            "loss: 0.205736  [32000/50000]\n",
            "loss: 0.220807  [38400/50000]\n",
            "loss: 0.496735  [44800/50000]\n",
            "Train Accuracy: 0.877220, Train Avg loss: 0.358278\n",
            "Test Accuracy: 0.886700, Test Avg loss: 0.353439 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.373023  [ 6400/50000]\n",
            "loss: 0.374611  [12800/50000]\n",
            "loss: 0.708316  [19200/50000]\n",
            "loss: 0.213600  [25600/50000]\n",
            "loss: 0.261742  [32000/50000]\n",
            "loss: 0.135082  [38400/50000]\n",
            "loss: 0.230626  [44800/50000]\n",
            "Train Accuracy: 0.879820, Train Avg loss: 0.348276\n",
            "Test Accuracy: 0.891900, Test Avg loss: 0.364494 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.442406  [ 6400/50000]\n",
            "loss: 0.199478  [12800/50000]\n",
            "loss: 0.325664  [19200/50000]\n",
            "loss: 0.158965  [25600/50000]\n",
            "loss: 0.205145  [32000/50000]\n",
            "loss: 0.498290  [38400/50000]\n",
            "loss: 0.565369  [44800/50000]\n",
            "Train Accuracy: 0.882460, Train Avg loss: 0.339521\n",
            "Test Accuracy: 0.891600, Test Avg loss: 0.351427 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.350370  [ 6400/50000]\n",
            "loss: 0.282974  [12800/50000]\n",
            "loss: 0.192300  [19200/50000]\n",
            "loss: 0.417211  [25600/50000]\n",
            "loss: 0.199979  [32000/50000]\n",
            "loss: 0.554236  [38400/50000]\n",
            "loss: 0.334441  [44800/50000]\n",
            "Train Accuracy: 0.884240, Train Avg loss: 0.338362\n",
            "Test Accuracy: 0.894800, Test Avg loss: 0.326321 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.361050  [ 6400/50000]\n",
            "loss: 0.458198  [12800/50000]\n",
            "loss: 0.423925  [19200/50000]\n",
            "loss: 0.257078  [25600/50000]\n",
            "loss: 0.466267  [32000/50000]\n",
            "loss: 0.441200  [38400/50000]\n",
            "loss: 0.282880  [44800/50000]\n",
            "Train Accuracy: 0.886800, Train Avg loss: 0.328317\n",
            "Test Accuracy: 0.891200, Test Avg loss: 0.347396 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.145212  [ 6400/50000]\n",
            "loss: 0.785809  [12800/50000]\n",
            "loss: 0.124484  [19200/50000]\n",
            "loss: 0.490820  [25600/50000]\n",
            "loss: 0.289968  [32000/50000]\n",
            "loss: 0.305804  [38400/50000]\n",
            "loss: 0.474629  [44800/50000]\n",
            "Train Accuracy: 0.889060, Train Avg loss: 0.318901\n",
            "Test Accuracy: 0.898700, Test Avg loss: 0.326425 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.256800  [ 6400/50000]\n",
            "loss: 0.302880  [12800/50000]\n",
            "loss: 0.095516  [19200/50000]\n",
            "loss: 0.384667  [25600/50000]\n",
            "loss: 0.532255  [32000/50000]\n",
            "loss: 0.499021  [38400/50000]\n",
            "loss: 0.261686  [44800/50000]\n",
            "Train Accuracy: 0.891960, Train Avg loss: 0.313977\n",
            "Test Accuracy: 0.897200, Test Avg loss: 0.323560 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.347611  [ 6400/50000]\n",
            "loss: 0.115990  [12800/50000]\n",
            "loss: 0.181957  [19200/50000]\n",
            "loss: 0.168107  [25600/50000]\n",
            "loss: 0.498314  [32000/50000]\n",
            "loss: 0.150851  [38400/50000]\n",
            "loss: 0.224678  [44800/50000]\n",
            "Train Accuracy: 0.892900, Train Avg loss: 0.306432\n",
            "Test Accuracy: 0.899500, Test Avg loss: 0.337053 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.206839  [ 6400/50000]\n",
            "loss: 0.379407  [12800/50000]\n",
            "loss: 0.328663  [19200/50000]\n",
            "loss: 0.307310  [25600/50000]\n",
            "loss: 0.373289  [32000/50000]\n",
            "loss: 0.187714  [38400/50000]\n",
            "loss: 0.122253  [44800/50000]\n",
            "Train Accuracy: 0.896620, Train Avg loss: 0.300609\n",
            "Model saved!\n",
            "Test Accuracy: 0.904200, Test Avg loss: 0.318614 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.348269  [ 6400/50000]\n",
            "loss: 0.331938  [12800/50000]\n",
            "loss: 0.167021  [19200/50000]\n",
            "loss: 0.219590  [25600/50000]\n",
            "loss: 0.184086  [32000/50000]\n",
            "loss: 0.372534  [38400/50000]\n",
            "loss: 0.245505  [44800/50000]\n",
            "Train Accuracy: 0.898620, Train Avg loss: 0.296758\n",
            "Model saved!\n",
            "Test Accuracy: 0.904300, Test Avg loss: 0.317607 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.300662  [ 6400/50000]\n",
            "loss: 0.487222  [12800/50000]\n",
            "loss: 0.216878  [19200/50000]\n",
            "loss: 0.360278  [25600/50000]\n",
            "loss: 0.111748  [32000/50000]\n",
            "loss: 0.117801  [38400/50000]\n",
            "loss: 0.284520  [44800/50000]\n",
            "Train Accuracy: 0.899200, Train Avg loss: 0.291228\n",
            "Test Accuracy: 0.903200, Test Avg loss: 0.322619 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.210450  [ 6400/50000]\n",
            "loss: 0.434528  [12800/50000]\n",
            "loss: 0.178230  [19200/50000]\n",
            "loss: 0.334473  [25600/50000]\n",
            "loss: 0.165885  [32000/50000]\n",
            "loss: 0.158565  [38400/50000]\n",
            "loss: 0.319316  [44800/50000]\n",
            "Train Accuracy: 0.903960, Train Avg loss: 0.277892\n",
            "Test Accuracy: 0.899100, Test Avg loss: 0.343050 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.240530  [ 6400/50000]\n",
            "loss: 0.256311  [12800/50000]\n",
            "loss: 0.130914  [19200/50000]\n",
            "loss: 0.344768  [25600/50000]\n",
            "loss: 0.543222  [32000/50000]\n",
            "loss: 0.430992  [38400/50000]\n",
            "loss: 0.237396  [44800/50000]\n",
            "Train Accuracy: 0.905020, Train Avg loss: 0.277094\n",
            "Test Accuracy: 0.899000, Test Avg loss: 0.351200 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.066504  [ 6400/50000]\n",
            "loss: 0.149244  [12800/50000]\n",
            "loss: 0.115207  [19200/50000]\n",
            "loss: 0.363497  [25600/50000]\n",
            "loss: 0.176039  [32000/50000]\n",
            "loss: 0.246017  [38400/50000]\n",
            "loss: 0.511475  [44800/50000]\n",
            "Train Accuracy: 0.903680, Train Avg loss: 0.278828\n",
            "Test Accuracy: 0.891600, Test Avg loss: 0.357051 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.367872  [ 6400/50000]\n",
            "loss: 0.186599  [12800/50000]\n",
            "loss: 0.123331  [19200/50000]\n",
            "loss: 0.411120  [25600/50000]\n",
            "loss: 0.475596  [32000/50000]\n",
            "loss: 0.083593  [38400/50000]\n",
            "loss: 0.533405  [44800/50000]\n",
            "Train Accuracy: 0.906660, Train Avg loss: 0.267325\n",
            "Test Accuracy: 0.898900, Test Avg loss: 0.343835 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.461106  [ 6400/50000]\n",
            "loss: 0.207927  [12800/50000]\n",
            "loss: 0.305696  [19200/50000]\n",
            "loss: 0.316470  [25600/50000]\n",
            "loss: 0.197853  [32000/50000]\n",
            "loss: 0.481880  [38400/50000]\n",
            "loss: 0.135564  [44800/50000]\n",
            "Train Accuracy: 0.908300, Train Avg loss: 0.264355\n",
            "Test Accuracy: 0.899700, Test Avg loss: 0.340982 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.346729  [ 6400/50000]\n",
            "loss: 0.496133  [12800/50000]\n",
            "loss: 0.102851  [19200/50000]\n",
            "loss: 0.319290  [25600/50000]\n",
            "loss: 0.202645  [32000/50000]\n",
            "loss: 0.167944  [38400/50000]\n",
            "loss: 0.129936  [44800/50000]\n",
            "Train Accuracy: 0.908320, Train Avg loss: 0.262367\n",
            "Test Accuracy: 0.902400, Test Avg loss: 0.344314 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.214227  [ 6400/50000]\n",
            "loss: 0.136739  [12800/50000]\n",
            "loss: 0.516396  [19200/50000]\n",
            "loss: 0.224479  [25600/50000]\n",
            "loss: 0.231196  [32000/50000]\n",
            "loss: 0.094408  [38400/50000]\n",
            "loss: 0.209119  [44800/50000]\n",
            "Train Accuracy: 0.908800, Train Avg loss: 0.257915\n",
            "Test Accuracy: 0.902000, Test Avg loss: 0.333838 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.263393  [ 6400/50000]\n",
            "loss: 0.396338  [12800/50000]\n",
            "loss: 0.266684  [19200/50000]\n",
            "loss: 0.326012  [25600/50000]\n",
            "loss: 0.327572  [32000/50000]\n",
            "loss: 0.336857  [38400/50000]\n",
            "loss: 0.125353  [44800/50000]\n",
            "Train Accuracy: 0.915280, Train Avg loss: 0.248186\n",
            "Test Accuracy: 0.904200, Test Avg loss: 0.349208 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.088398  [ 6400/50000]\n",
            "loss: 0.286217  [12800/50000]\n",
            "loss: 0.201174  [19200/50000]\n",
            "loss: 0.320048  [25600/50000]\n",
            "loss: 0.337508  [32000/50000]\n",
            "loss: 0.466207  [38400/50000]\n",
            "loss: 0.346719  [44800/50000]\n",
            "Train Accuracy: 0.914220, Train Avg loss: 0.251585\n",
            "Model saved!\n",
            "Test Accuracy: 0.905600, Test Avg loss: 0.339591 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.388881  [ 6400/50000]\n",
            "loss: 0.267260  [12800/50000]\n",
            "loss: 0.314566  [19200/50000]\n",
            "loss: 0.605920  [25600/50000]\n",
            "loss: 0.220758  [32000/50000]\n",
            "loss: 0.226061  [38400/50000]\n",
            "loss: 0.193649  [44800/50000]\n",
            "Train Accuracy: 0.915300, Train Avg loss: 0.244898\n",
            "Model saved!\n",
            "Test Accuracy: 0.906500, Test Avg loss: 0.325515 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.363669  [ 6400/50000]\n",
            "loss: 0.175381  [12800/50000]\n",
            "loss: 0.283477  [19200/50000]\n",
            "loss: 0.223086  [25600/50000]\n",
            "loss: 0.481773  [32000/50000]\n",
            "loss: 0.222019  [38400/50000]\n",
            "loss: 0.217086  [44800/50000]\n",
            "Train Accuracy: 0.916300, Train Avg loss: 0.239775\n",
            "Test Accuracy: 0.905600, Test Avg loss: 0.336848 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.161849  [ 6400/50000]\n",
            "loss: 0.481105  [12800/50000]\n",
            "loss: 0.094105  [19200/50000]\n",
            "loss: 0.115712  [25600/50000]\n",
            "loss: 0.043832  [32000/50000]\n",
            "loss: 0.150772  [38400/50000]\n",
            "loss: 0.608156  [44800/50000]\n",
            "Train Accuracy: 0.918780, Train Avg loss: 0.233575\n",
            "Test Accuracy: 0.900400, Test Avg loss: 0.360723 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.055384  [ 6400/50000]\n",
            "loss: 0.233023  [12800/50000]\n",
            "loss: 0.050559  [19200/50000]\n",
            "loss: 0.262647  [25600/50000]\n",
            "loss: 0.146076  [32000/50000]\n",
            "loss: 0.197695  [38400/50000]\n",
            "loss: 0.290824  [44800/50000]\n",
            "Train Accuracy: 0.921860, Train Avg loss: 0.228189\n",
            "Test Accuracy: 0.900100, Test Avg loss: 0.367124 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.301346  [ 6400/50000]\n",
            "loss: 0.062223  [12800/50000]\n",
            "loss: 0.294003  [19200/50000]\n",
            "loss: 0.233626  [25600/50000]\n",
            "loss: 0.416166  [32000/50000]\n",
            "loss: 0.120178  [38400/50000]\n",
            "loss: 0.391931  [44800/50000]\n",
            "Train Accuracy: 0.921600, Train Avg loss: 0.226539\n",
            "Test Accuracy: 0.906200, Test Avg loss: 0.332139 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.259954  [ 6400/50000]\n",
            "loss: 0.317318  [12800/50000]\n",
            "loss: 0.277539  [19200/50000]\n",
            "loss: 0.354556  [25600/50000]\n",
            "loss: 0.297466  [32000/50000]\n",
            "loss: 0.201072  [38400/50000]\n",
            "loss: 0.063681  [44800/50000]\n",
            "Train Accuracy: 0.922420, Train Avg loss: 0.225022\n",
            "Model saved!\n",
            "Test Accuracy: 0.906800, Test Avg loss: 0.338533 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.051855  [ 6400/50000]\n",
            "loss: 0.128128  [12800/50000]\n",
            "loss: 0.297617  [19200/50000]\n",
            "loss: 0.184564  [25600/50000]\n",
            "loss: 0.101996  [32000/50000]\n",
            "loss: 0.122615  [38400/50000]\n",
            "loss: 0.197292  [44800/50000]\n",
            "Train Accuracy: 0.922100, Train Avg loss: 0.227580\n",
            "Model saved!\n",
            "Test Accuracy: 0.912000, Test Avg loss: 0.313990 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.102490  [ 6400/50000]\n",
            "loss: 0.363160  [12800/50000]\n",
            "loss: 0.093510  [19200/50000]\n",
            "loss: 0.139552  [25600/50000]\n",
            "loss: 0.340246  [32000/50000]\n",
            "loss: 0.182038  [38400/50000]\n",
            "loss: 0.285116  [44800/50000]\n",
            "Train Accuracy: 0.924280, Train Avg loss: 0.217602\n",
            "Test Accuracy: 0.910100, Test Avg loss: 0.324270 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.205154  [ 6400/50000]\n",
            "loss: 0.356777  [12800/50000]\n",
            "loss: 0.068361  [19200/50000]\n",
            "loss: 0.104477  [25600/50000]\n",
            "loss: 0.158932  [32000/50000]\n",
            "loss: 0.088389  [38400/50000]\n",
            "loss: 0.165813  [44800/50000]\n",
            "Train Accuracy: 0.925500, Train Avg loss: 0.217677\n",
            "Test Accuracy: 0.911100, Test Avg loss: 0.338141 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.155405  [ 6400/50000]\n",
            "loss: 0.215266  [12800/50000]\n",
            "loss: 0.411410  [19200/50000]\n",
            "loss: 0.381973  [25600/50000]\n",
            "loss: 0.145384  [32000/50000]\n",
            "loss: 0.417196  [38400/50000]\n",
            "loss: 0.233799  [44800/50000]\n",
            "Train Accuracy: 0.928320, Train Avg loss: 0.208822\n",
            "Test Accuracy: 0.907200, Test Avg loss: 0.347806 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.239048  [ 6400/50000]\n",
            "loss: 0.267542  [12800/50000]\n",
            "loss: 0.180643  [19200/50000]\n",
            "loss: 0.068681  [25600/50000]\n",
            "loss: 0.067862  [32000/50000]\n",
            "loss: 0.140851  [38400/50000]\n",
            "loss: 0.205003  [44800/50000]\n",
            "Train Accuracy: 0.925980, Train Avg loss: 0.209979\n",
            "Test Accuracy: 0.904100, Test Avg loss: 0.356268 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.225792  [ 6400/50000]\n",
            "loss: 0.097210  [12800/50000]\n",
            "loss: 0.044607  [19200/50000]\n",
            "loss: 0.198693  [25600/50000]\n",
            "loss: 0.088881  [32000/50000]\n",
            "loss: 0.391883  [38400/50000]\n",
            "loss: 0.118309  [44800/50000]\n",
            "Train Accuracy: 0.927020, Train Avg loss: 0.213464\n",
            "Test Accuracy: 0.902800, Test Avg loss: 0.362845 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.091709  [ 6400/50000]\n",
            "loss: 0.201022  [12800/50000]\n",
            "loss: 0.283905  [19200/50000]\n",
            "loss: 0.203809  [25600/50000]\n",
            "loss: 0.262909  [32000/50000]\n",
            "loss: 0.433164  [38400/50000]\n",
            "loss: 0.134326  [44800/50000]\n",
            "Train Accuracy: 0.928920, Train Avg loss: 0.208166\n",
            "Test Accuracy: 0.903600, Test Avg loss: 0.375550 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.219270  [ 6400/50000]\n",
            "loss: 0.463475  [12800/50000]\n",
            "loss: 0.190177  [19200/50000]\n",
            "loss: 0.534667  [25600/50000]\n",
            "loss: 0.313975  [32000/50000]\n",
            "loss: 0.066768  [38400/50000]\n",
            "loss: 0.345553  [44800/50000]\n",
            "Train Accuracy: 0.929540, Train Avg loss: 0.201594\n",
            "Test Accuracy: 0.904900, Test Avg loss: 0.350011 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.143824  [ 6400/50000]\n",
            "loss: 0.275749  [12800/50000]\n",
            "loss: 0.258814  [19200/50000]\n",
            "loss: 0.056358  [25600/50000]\n",
            "loss: 0.173847  [32000/50000]\n",
            "loss: 0.118876  [38400/50000]\n",
            "loss: 0.037669  [44800/50000]\n",
            "Train Accuracy: 0.930420, Train Avg loss: 0.199472\n",
            "Test Accuracy: 0.905400, Test Avg loss: 0.356337 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.542633  [ 6400/50000]\n",
            "loss: 0.238315  [12800/50000]\n",
            "loss: 0.062399  [19200/50000]\n",
            "loss: 0.175020  [25600/50000]\n",
            "loss: 0.080380  [32000/50000]\n",
            "loss: 0.290808  [38400/50000]\n",
            "loss: 0.274622  [44800/50000]\n",
            "Train Accuracy: 0.932320, Train Avg loss: 0.198671\n",
            "Model saved!\n",
            "Test Accuracy: 0.913700, Test Avg loss: 0.349695 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.222669  [ 6400/50000]\n",
            "loss: 0.186378  [12800/50000]\n",
            "loss: 0.152422  [19200/50000]\n",
            "loss: 0.257264  [25600/50000]\n",
            "loss: 0.247293  [32000/50000]\n",
            "loss: 0.093619  [38400/50000]\n",
            "loss: 0.141484  [44800/50000]\n",
            "Train Accuracy: 0.932560, Train Avg loss: 0.197809\n",
            "Test Accuracy: 0.912800, Test Avg loss: 0.343739 \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished. The highest validation accuracy is 0.9137.\n"
          ]
        }
      ],
      "source": [
        "# Use GPU for training if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "\n",
        "# The following line is for training with Apple silicon\n",
        "#device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "\n",
        "print('Using device:', device)\n",
        "if torch.cuda.is_available(): print(torch.cuda.get_device_name(0)) # print the type of the chosen gpu\n",
        "\n",
        "train_loop(train_iter, test_iter, net, num_epochs, loss, optimizer, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a3926111",
      "metadata": {
        "id": "a3926111"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}